{"timestamp":"2025-09-02T15:46:40.966956","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-09-02T15:46:40.967526","level":"info","event":"Filling up the DagBag from /opt/bitnami/airflow/dags/rt_pipeline.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-02T15:46:41.004083Z","level":"info","event":"Task instance is in running state","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-02T15:46:41.004595Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-02T15:46:41.005126Z","level":"info","event":"Current task name:orders_bronze_stream","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-02T15:46:41.005581Z","level":"info","event":"Dag name:bronze_streams","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-02T15:46:41.004858","level":"info","event":"Tmp dir root location: /tmp","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:41.005433","level":"info","event":"Running command: ['/usr/bin/bash', '-c', '/opt/spark/bin/spark-submit --master spark://spark-master:7077 --deploy-mode client /opt/jobs/bronze_orders.py']","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:41.013290","level":"info","event":"Output:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:42.997858","level":"info","event":"25/09/02 15:46:42 INFO SparkContext: Running Spark version 3.5.1","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:42.999653","level":"info","event":"25/09/02 15:46:42 INFO SparkContext: OS info Linux, 5.15.167.4-microsoft-standard-WSL2, amd64","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:42.999797","level":"info","event":"25/09/02 15:46:42 INFO SparkContext: Java version 17.0.16","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.038639","level":"info","event":"25/09/02 15:46:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.094210","level":"info","event":"25/09/02 15:46:43 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.094377","level":"info","event":"25/09/02 15:46:43 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.094881","level":"info","event":"25/09/02 15:46:43 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.095309","level":"info","event":"25/09/02 15:46:43 INFO SparkContext: Submitted application: bronze-orders","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.110023","level":"info","event":"25/09/02 15:46:43 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.115456","level":"info","event":"25/09/02 15:46:43 INFO ResourceProfile: Limiting resource is cpu","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.116073","level":"info","event":"25/09/02 15:46:43 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.147143","level":"info","event":"25/09/02 15:46:43 INFO SecurityManager: Changing view acls to: root","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.147330","level":"info","event":"25/09/02 15:46:43 INFO SecurityManager: Changing modify acls to: root","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.147749","level":"info","event":"25/09/02 15:46:43 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.148276","level":"info","event":"25/09/02 15:46:43 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.148619","level":"info","event":"25/09/02 15:46:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root; groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.348348","level":"info","event":"25/09/02 15:46:43 INFO Utils: Successfully started service 'sparkDriver' on port 41737.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.376139","level":"info","event":"25/09/02 15:46:43 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.405717","level":"info","event":"25/09/02 15:46:43 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.423100","level":"info","event":"25/09/02 15:46:43 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.424043","level":"info","event":"25/09/02 15:46:43 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.428622","level":"info","event":"25/09/02 15:46:43 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.453364","level":"info","event":"25/09/02 15:46:43 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-91497bcd-94e9-4975-a1c1-bfcc9f493580","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.469128","level":"info","event":"25/09/02 15:46:43 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.487534","level":"info","event":"25/09/02 15:46:43 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.584075","level":"info","event":"25/09/02 15:46:43 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.627413","level":"info","event":"25/09/02 15:46:43 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.635339","level":"info","event":"25/09/02 15:46:43 INFO Utils: Successfully started service 'SparkUI' on port 4041.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.731457","level":"info","event":"25/09/02 15:46:43 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.766728","level":"info","event":"25/09/02 15:46:43 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.24:7077 after 19 ms (0 ms spent in bootstraps)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.840625","level":"info","event":"25/09/02 15:46:43 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250902154643-0005","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.849113","level":"info","event":"25/09/02 15:46:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42207.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.849302","level":"info","event":"25/09/02 15:46:43 INFO NettyBlockTransferService: Server created on b1b4c0de2c56:42207","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.850861","level":"info","event":"25/09/02 15:46:43 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.856028","level":"info","event":"25/09/02 15:46:43 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, b1b4c0de2c56, 42207, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.859155","level":"info","event":"25/09/02 15:46:43 INFO BlockManagerMasterEndpoint: Registering block manager b1b4c0de2c56:42207 with 434.4 MiB RAM, BlockManagerId(driver, b1b4c0de2c56, 42207, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.861142","level":"info","event":"25/09/02 15:46:43 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, b1b4c0de2c56, 42207, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:43.862147","level":"info","event":"25/09/02 15:46:43 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, b1b4c0de2c56, 42207, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:44.035822","level":"info","event":"25/09/02 15:46:44 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:44.211186","level":"info","event":"INFO:__main__:Spark session started","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:44.252102","level":"info","event":"25/09/02 15:46:44 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:44.257838","level":"info","event":"25/09/02 15:46:44 INFO SharedState: Warehouse path is 'file:/tmp/airflowtmp6ywx_ejz/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.116457","level":"info","event":"ERROR:__main__:Fatal error in bronze-orders: Failed to find data source: kafka. Please deploy the application as per the deployment section of Structured Streaming + Kafka Integration Guide.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.116679","level":"info","event":"Traceback (most recent call last):","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.116775","level":"info","event":"  File \"/opt/jobs/bronze_orders.py\", line 49, in main","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.116845","level":"info","event":"    .load())","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.116914","level":"info","event":"     ^^^^^^","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.116987","level":"info","event":"  File \"/opt/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py\", line 304, in load","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.117048","level":"info","event":"    return self._df(self._jreader.load())","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.117108","level":"info","event":"                    ^^^^^^^^^^^^^^^^^^^^","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.117154","level":"info","event":"  File \"/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1322, in __call__","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.117192","level":"info","event":"    return_value = get_return_value(","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.117230","level":"info","event":"                   ^^^^^^^^^^^^^^^^^","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.117274","level":"info","event":"  File \"/opt/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py\", line 185, in deco","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.117339","level":"info","event":"    raise converted from None","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.117384","level":"info","event":"pyspark.errors.exceptions.captured.AnalysisException: Failed to find data source: kafka. Please deploy the application as per the deployment section of Structured Streaming + Kafka Integration Guide.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.117440","level":"info","event":"Traceback (most recent call last):","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.117555","level":"info","event":"  File \"/opt/jobs/bronze_orders.py\", line 72, in <module>","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.118037","level":"info","event":"    main()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.118108","level":"info","event":"  File \"/opt/jobs/bronze_orders.py\", line 49, in main","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.119989","level":"info","event":"    .load())","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.120107","level":"info","event":"     ^^^^^^","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.120158","level":"info","event":"  File \"/opt/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py\", line 304, in load","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.120284","level":"info","event":"  File \"/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1322, in __call__","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.120592","level":"info","event":"  File \"/opt/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py\", line 185, in deco","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.123442","level":"info","event":"pyspark.errors.exceptions.captured.AnalysisException: Failed to find data source: kafka. Please deploy the application as per the deployment section of Structured Streaming + Kafka Integration Guide.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.123598","level":"info","event":"INFO:py4j.clientserver:Closing down clientserver connection","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.165631","level":"info","event":"25/09/02 15:46:45 INFO SparkContext: Invoking stop() from shutdown hook","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.165900","level":"info","event":"25/09/02 15:46:45 INFO SparkContext: SparkContext is stopping with exitCode 0.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.173686","level":"info","event":"25/09/02 15:46:45 INFO SparkUI: Stopped Spark web UI at http://b1b4c0de2c56:4041","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.177075","level":"info","event":"25/09/02 15:46:45 INFO StandaloneSchedulerBackend: Shutting down all executors","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.179650","level":"info","event":"25/09/02 15:46:45 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.186939","level":"info","event":"25/09/02 15:46:45 ERROR TransportRequestHandler: Error while invoking RpcHandler#receive() for one-way message.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.187144","level":"info","event":"org.apache.spark.SparkException: Could not find AppClient.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.187255","level":"info","event":"\tat org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:178)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.187333","level":"info","event":"\tat org.apache.spark.rpc.netty.Dispatcher.postOneWayMessage(Dispatcher.scala:150)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.187401","level":"info","event":"\tat org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:690)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.187497","level":"info","event":"\tat org.apache.spark.network.server.TransportRequestHandler.processOneWayMessage(TransportRequestHandler.java:274)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.187580","level":"info","event":"\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:111)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.187655","level":"info","event":"\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.187732","level":"info","event":"\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.187795","level":"info","event":"\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.187853","level":"info","event":"\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.187923","level":"info","event":"\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.187985","level":"info","event":"\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.188043","level":"info","event":"\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.188105","level":"info","event":"\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.188164","level":"info","event":"\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.188221","level":"info","event":"\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.188278","level":"info","event":"\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.188337","level":"info","event":"\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.188400","level":"info","event":"\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.188463","level":"info","event":"\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.188560","level":"info","event":"\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.188638","level":"info","event":"\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.188746","level":"info","event":"\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.188814","level":"info","event":"\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.188876","level":"info","event":"\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.188941","level":"info","event":"\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.189007","level":"info","event":"\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.189074","level":"info","event":"\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.189138","level":"info","event":"\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.189200","level":"info","event":"\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.189266","level":"info","event":"\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.189326","level":"info","event":"\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.189388","level":"info","event":"\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.189475","level":"info","event":"\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.189562","level":"info","event":"\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.189636","level":"info","event":"\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.189702","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.193175","level":"info","event":"25/09/02 15:46:45 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.203301","level":"info","event":"25/09/02 15:46:45 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.203820","level":"info","event":"25/09/02 15:46:45 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.212020","level":"info","event":"25/09/02 15:46:45 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.213746","level":"info","event":"25/09/02 15:46:45 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.222151","level":"info","event":"25/09/02 15:46:45 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.222485","level":"info","event":"25/09/02 15:46:45 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.222988","level":"info","event":"25/09/02 15:46:45 INFO ShutdownHookManager: Deleting directory /tmp/spark-ad796043-aade-465b-be51-2a9c1053b730","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.225734","level":"info","event":"25/09/02 15:46:45 INFO ShutdownHookManager: Deleting directory /tmp/spark-0f4da99a-51de-4086-93a1-602c68e357c6","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.228177","level":"info","event":"25/09/02 15:46:45 INFO ShutdownHookManager: Deleting directory /tmp/spark-ad796043-aade-465b-be51-2a9c1053b730/pyspark-aaa57e4f-832d-4781-90c8-d7121563e125","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.247032","level":"info","event":"Command exited with return code 1","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:46:45.247711","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"AirflowException","exc_value":"Bash command failed. The command returned a non-zero exit code 1.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/opt/bitnami/airflow/venv/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":918,"name":"run"},{"filename":"/opt/bitnami/airflow/venv/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1213,"name":"_execute_task"},{"filename":"/opt/bitnami/airflow/venv/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":397,"name":"wrapper"},{"filename":"/opt/bitnami/airflow/venv/lib/python3.12/site-packages/airflow/providers/standard/operators/bash.py","lineno":232,"name":"execute"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2025-09-02T15:46:45.249400Z","level":"info","event":"Task instance in failure state","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-02T15:46:45.249785Z","level":"info","event":"Task start","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-02T15:46:45.250031Z","level":"info","event":"Task:<Task(BashOperator): orders_bronze_stream>","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-02T15:46:45.250201Z","level":"info","event":"Failure caused by Bash command failed. The command returned a non-zero exit code 1.","chan":"stdout","logger":"task"}

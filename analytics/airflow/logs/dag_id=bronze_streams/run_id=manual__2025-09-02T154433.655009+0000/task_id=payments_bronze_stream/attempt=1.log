{"timestamp":"2025-09-02T15:44:35.590693","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-09-02T15:44:35.591570","level":"info","event":"Filling up the DagBag from /opt/bitnami/airflow/dags/rt_pipeline.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-02T15:44:36.398033Z","level":"info","event":"Task instance is in running state","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-02T15:44:36.398505Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-02T15:44:36.398746Z","level":"info","event":"Current task name:payments_bronze_stream","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-02T15:44:36.398941Z","level":"info","event":"Dag name:bronze_streams","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-02T15:44:36.399286","level":"info","event":"Tmp dir root location: /tmp","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:36.399997","level":"info","event":"Running command: ['/usr/bin/bash', '-c', '/opt/spark/bin/spark-submit --master spark://spark-master:7077 --deploy-mode client /opt/jobs/bronze_payments.py']","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:36.407631","level":"info","event":"Output:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:38.320743","level":"info","event":"25/09/02 15:44:38 INFO SparkContext: Running Spark version 3.5.1","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:38.322175","level":"info","event":"25/09/02 15:44:38 INFO SparkContext: OS info Linux, 5.15.167.4-microsoft-standard-WSL2, amd64","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:38.322320","level":"info","event":"25/09/02 15:44:38 INFO SparkContext: Java version 17.0.16","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:38.356585","level":"info","event":"25/09/02 15:44:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:38.415793","level":"info","event":"25/09/02 15:44:38 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:38.416005","level":"info","event":"25/09/02 15:44:38 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:38.416498","level":"info","event":"25/09/02 15:44:38 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:38.416849","level":"info","event":"25/09/02 15:44:38 INFO SparkContext: Submitted application: bronze-payments","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:38.430412","level":"info","event":"25/09/02 15:44:38 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:38.435915","level":"info","event":"25/09/02 15:44:38 INFO ResourceProfile: Limiting resource is cpu","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:38.436462","level":"info","event":"25/09/02 15:44:38 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:38.466602","level":"info","event":"25/09/02 15:44:38 INFO SecurityManager: Changing view acls to: root","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:38.467230","level":"info","event":"25/09/02 15:44:38 INFO SecurityManager: Changing modify acls to: root","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:38.467729","level":"info","event":"25/09/02 15:44:38 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:38.468095","level":"info","event":"25/09/02 15:44:38 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:38.468507","level":"info","event":"25/09/02 15:44:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root; groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:38.641406","level":"info","event":"25/09/02 15:44:38 INFO Utils: Successfully started service 'sparkDriver' on port 35185.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:38.660699","level":"info","event":"25/09/02 15:44:38 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:38.686722","level":"info","event":"25/09/02 15:44:38 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:38.700939","level":"info","event":"25/09/02 15:44:38 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:38.701448","level":"info","event":"25/09/02 15:44:38 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:38.704621","level":"info","event":"25/09/02 15:44:38 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:38.721871","level":"info","event":"25/09/02 15:44:38 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2d96273a-2246-47b0-8f63-8b842f7f43b6","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:38.736116","level":"info","event":"25/09/02 15:44:38 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:38.755763","level":"info","event":"25/09/02 15:44:38 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:38.869106","level":"info","event":"25/09/02 15:44:38 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:38.914097","level":"info","event":"25/09/02 15:44:38 INFO Utils: Successfully started service 'SparkUI' on port 4040.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:39.008905","level":"info","event":"25/09/02 15:44:39 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:39.051824","level":"info","event":"25/09/02 15:44:39 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.24:7077 after 24 ms (0 ms spent in bootstraps)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:39.131095","level":"info","event":"25/09/02 15:44:39 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250902154439-0002","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:39.132643","level":"info","event":"25/09/02 15:44:39 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250902154439-0002/0 on worker-20250902084047-172.18.0.14-36917 (172.18.0.14:36917) with 2 core(s)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:39.134166","level":"info","event":"25/09/02 15:44:39 INFO StandaloneSchedulerBackend: Granted executor ID app-20250902154439-0002/0 on hostPort 172.18.0.14:36917 with 2 core(s), 1024.0 MiB RAM","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:39.138198","level":"info","event":"25/09/02 15:44:39 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36223.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:39.138366","level":"info","event":"25/09/02 15:44:39 INFO NettyBlockTransferService: Server created on b1b4c0de2c56:36223","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:39.139983","level":"info","event":"25/09/02 15:44:39 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:39.144560","level":"info","event":"25/09/02 15:44:39 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, b1b4c0de2c56, 36223, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:39.146952","level":"info","event":"25/09/02 15:44:39 INFO BlockManagerMasterEndpoint: Registering block manager b1b4c0de2c56:36223 with 434.4 MiB RAM, BlockManagerId(driver, b1b4c0de2c56, 36223, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:39.148680","level":"info","event":"25/09/02 15:44:39 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, b1b4c0de2c56, 36223, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:39.149721","level":"info","event":"25/09/02 15:44:39 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, b1b4c0de2c56, 36223, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:39.173287","level":"info","event":"25/09/02 15:44:39 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250902154439-0002/0 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:39.329552","level":"info","event":"25/09/02 15:44:39 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:39.488065","level":"info","event":"INFO:__main__:Spark session started","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:39.536325","level":"info","event":"25/09/02 15:44:39 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:39.541642","level":"info","event":"25/09/02 15:44:39 INFO SharedState: Warehouse path is 'file:/tmp/airflowtmpyw9chbev/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.427853","level":"info","event":"ERROR:__main__:Fatal error in bronze-payments: Failed to find data source: kafka. Please deploy the application as per the deployment section of Structured Streaming + Kafka Integration Guide.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.428073","level":"info","event":"Traceback (most recent call last):","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.428147","level":"info","event":"  File \"/opt/jobs/bronze_payments.py\", line 43, in main","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.428224","level":"info","event":"    .load())","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.428295","level":"info","event":"     ^^^^^^","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.428370","level":"info","event":"  File \"/opt/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py\", line 304, in load","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.428442","level":"info","event":"    return self._df(self._jreader.load())","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.428522","level":"info","event":"                    ^^^^^^^^^^^^^^^^^^^^","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.428633","level":"info","event":"  File \"/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1322, in __call__","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.428703","level":"info","event":"    return_value = get_return_value(","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.428759","level":"info","event":"                   ^^^^^^^^^^^^^^^^^","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.428813","level":"info","event":"  File \"/opt/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py\", line 185, in deco","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.428872","level":"info","event":"    raise converted from None","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.428932","level":"info","event":"pyspark.errors.exceptions.captured.AnalysisException: Failed to find data source: kafka. Please deploy the application as per the deployment section of Structured Streaming + Kafka Integration Guide.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.429005","level":"info","event":"Traceback (most recent call last):","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.429072","level":"info","event":"  File \"/opt/jobs/bronze_payments.py\", line 66, in <module>","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.430405","level":"info","event":"    main()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.430542","level":"info","event":"  File \"/opt/jobs/bronze_payments.py\", line 43, in main","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.432668","level":"info","event":"    .load())","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.432782","level":"info","event":"     ^^^^^^","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.432834","level":"info","event":"  File \"/opt/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py\", line 304, in load","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.432880","level":"info","event":"  File \"/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1322, in __call__","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.433339","level":"info","event":"  File \"/opt/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py\", line 185, in deco","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.437986","level":"info","event":"pyspark.errors.exceptions.captured.AnalysisException: Failed to find data source: kafka. Please deploy the application as per the deployment section of Structured Streaming + Kafka Integration Guide.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.438235","level":"info","event":"INFO:py4j.clientserver:Closing down clientserver connection","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.483297","level":"info","event":"25/09/02 15:44:40 INFO SparkContext: Invoking stop() from shutdown hook","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.483573","level":"info","event":"25/09/02 15:44:40 INFO SparkContext: SparkContext is stopping with exitCode 0.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.490886","level":"info","event":"25/09/02 15:44:40 INFO SparkUI: Stopped Spark web UI at http://b1b4c0de2c56:4040","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.494006","level":"info","event":"25/09/02 15:44:40 INFO StandaloneSchedulerBackend: Shutting down all executors","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.496817","level":"info","event":"25/09/02 15:44:40 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.507497","level":"info","event":"25/09/02 15:44:40 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.518030","level":"info","event":"25/09/02 15:44:40 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.518419","level":"info","event":"25/09/02 15:44:40 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.522689","level":"info","event":"25/09/02 15:44:40 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.524667","level":"info","event":"25/09/02 15:44:40 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.536871","level":"info","event":"25/09/02 15:44:40 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.537543","level":"info","event":"25/09/02 15:44:40 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.538032","level":"info","event":"25/09/02 15:44:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-3d7f4e1c-a97c-4b36-ba88-2b3704a8f181/pyspark-16b23ee7-3628-43b9-a828-42a58b20a93d","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.540881","level":"info","event":"25/09/02 15:44:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-bed4a7f1-0ba8-410e-9e01-863db0ad1d01","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.543099","level":"info","event":"25/09/02 15:44:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-3d7f4e1c-a97c-4b36-ba88-2b3704a8f181","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.572361","level":"info","event":"Command exited with return code 1","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T15:44:40.572820","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"AirflowException","exc_value":"Bash command failed. The command returned a non-zero exit code 1.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/opt/bitnami/airflow/venv/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":918,"name":"run"},{"filename":"/opt/bitnami/airflow/venv/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1213,"name":"_execute_task"},{"filename":"/opt/bitnami/airflow/venv/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":397,"name":"wrapper"},{"filename":"/opt/bitnami/airflow/venv/lib/python3.12/site-packages/airflow/providers/standard/operators/bash.py","lineno":232,"name":"execute"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2025-09-02T15:44:40.597104Z","level":"info","event":"Task instance in failure state","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-02T15:44:40.597476Z","level":"info","event":"Task start","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-02T15:44:40.597722Z","level":"info","event":"Task:<Task(BashOperator): payments_bronze_stream>","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-02T15:44:40.597995Z","level":"info","event":"Failure caused by Bash command failed. The command returned a non-zero exit code 1.","chan":"stdout","logger":"task"}

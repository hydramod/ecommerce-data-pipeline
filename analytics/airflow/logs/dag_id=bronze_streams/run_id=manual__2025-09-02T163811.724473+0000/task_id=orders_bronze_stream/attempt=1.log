{"timestamp":"2025-09-02T16:38:11.869892","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-09-02T16:38:11.870771","level":"info","event":"Filling up the DagBag from /opt/bitnami/airflow/dags/rt_pipeline.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-02T16:38:11.927341Z","level":"info","event":"Task instance is in running state","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-02T16:38:11.927658Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-02T16:38:11.927871Z","level":"info","event":"Current task name:orders_bronze_stream","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-02T16:38:11.928037Z","level":"info","event":"Dag name:bronze_streams","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-02T16:38:11.928376","level":"info","event":"Tmp dir root location: /tmp","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:11.929228","level":"info","event":"Running command: ['/usr/bin/bash', '-c', '/opt/spark/bin/spark-submit --master spark://spark-master:7077 --deploy-mode client --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0 /opt/jobs/bronze_orders.py']","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:11.942713","level":"info","event":"Output:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.129529","level":"info","event":":: loading settings :: url = jar:file:/opt/spark-3.5.1-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.174738","level":"info","event":"Ivy Default Cache set to: /root/.ivy2/cache","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.174956","level":"info","event":"The jars for the packages stored in: /root/.ivy2/jars","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.178412","level":"info","event":"org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.179042","level":"info","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-075a4d9d-5cc9-4f09-81d9-784406f40b28;1.0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.179174","level":"info","event":"\tconfs: [default]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.312400","level":"info","event":"\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 in central","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.374152","level":"info","event":"\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 in central","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.401432","level":"info","event":"\tfound org.apache.kafka#kafka-clients;3.4.1 in central","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.431397","level":"info","event":"\tfound org.lz4#lz4-java;1.8.0 in central","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.463941","level":"info","event":"\tfound org.xerial.snappy#snappy-java;1.1.10.3 in central","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.488761","level":"info","event":"\tfound org.slf4j#slf4j-api;2.0.7 in central","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.518739","level":"info","event":"\tfound org.apache.hadoop#hadoop-client-runtime;3.3.4 in central","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.545502","level":"info","event":"\tfound org.apache.hadoop#hadoop-client-api;3.3.4 in central","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.573629","level":"info","event":"\tfound commons-logging#commons-logging;1.1.3 in central","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.595165","level":"info","event":"\tfound com.google.code.findbugs#jsr305;3.0.0 in central","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.610406","level":"info","event":"\tfound org.apache.commons#commons-pool2;2.11.1 in central","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.649086","level":"info","event":":: resolution report :: resolve 450ms :: artifacts dl 20ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.649712","level":"info","event":"\t:: modules in use:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.649834","level":"info","event":"\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.649904","level":"info","event":"\tcommons-logging#commons-logging;1.1.3 from central in [default]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.650051","level":"info","event":"\torg.apache.commons#commons-pool2;2.11.1 from central in [default]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.650257","level":"info","event":"\torg.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.650333","level":"info","event":"\torg.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.650402","level":"info","event":"\torg.apache.kafka#kafka-clients;3.4.1 from central in [default]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.650469","level":"info","event":"\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.650537","level":"info","event":"\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.650605","level":"info","event":"\torg.lz4#lz4-java;1.8.0 from central in [default]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.650671","level":"info","event":"\torg.slf4j#slf4j-api;2.0.7 from central in [default]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.650742","level":"info","event":"\torg.xerial.snappy#snappy-java;1.1.10.3 from central in [default]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.650974","level":"info","event":"\t---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.651070","level":"info","event":"\t|                  |            modules            ||   artifacts   |","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.651248","level":"info","event":"\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.651521","level":"info","event":"\t---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.651618","level":"info","event":"\t|      default     |   11  |   0   |   0   |   0   ||   11  |   0   |","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.651695","level":"info","event":"\t---------------------------------------------------------------------","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.658048","level":"info","event":":: retrieving :: org.apache.spark#spark-submit-parent-075a4d9d-5cc9-4f09-81d9-784406f40b28","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.658252","level":"info","event":"\tconfs: [default]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.668369","level":"info","event":"\t0 artifacts copied, 11 already retrieved (0kB/11ms)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:13.843702","level":"info","event":"25/09/02 16:38:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:14.949318","level":"info","event":"25/09/02 16:38:14 INFO SparkContext: Running Spark version 3.5.1","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:14.949687","level":"info","event":"25/09/02 16:38:14 INFO SparkContext: OS info Linux, 5.15.167.4-microsoft-standard-WSL2, amd64","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:14.949915","level":"info","event":"25/09/02 16:38:14 INFO SparkContext: Java version 17.0.16","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:14.967732","level":"info","event":"25/09/02 16:38:14 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:14.967939","level":"info","event":"25/09/02 16:38:14 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:14.968264","level":"info","event":"25/09/02 16:38:14 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:14.968529","level":"info","event":"25/09/02 16:38:14 INFO SparkContext: Submitted application: bronze-orders","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:14.988518","level":"info","event":"25/09/02 16:38:14 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:14.998317","level":"info","event":"25/09/02 16:38:14 INFO ResourceProfile: Limiting resource is cpu","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:14.999318","level":"info","event":"25/09/02 16:38:14 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.053658","level":"info","event":"25/09/02 16:38:15 INFO SecurityManager: Changing view acls to: root","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.054261","level":"info","event":"25/09/02 16:38:15 INFO SecurityManager: Changing modify acls to: root","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.055147","level":"info","event":"25/09/02 16:38:15 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.056073","level":"info","event":"25/09/02 16:38:15 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.056877","level":"info","event":"25/09/02 16:38:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root; groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.247569","level":"info","event":"25/09/02 16:38:15 INFO Utils: Successfully started service 'sparkDriver' on port 41193.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.284299","level":"info","event":"25/09/02 16:38:15 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.315630","level":"info","event":"25/09/02 16:38:15 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.327954","level":"info","event":"25/09/02 16:38:15 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.328388","level":"info","event":"25/09/02 16:38:15 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.332129","level":"info","event":"25/09/02 16:38:15 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.349911","level":"info","event":"25/09/02 16:38:15 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-12b6ae7f-6f87-4357-8992-a0059e400eb5","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.362931","level":"info","event":"25/09/02 16:38:15 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.379545","level":"info","event":"25/09/02 16:38:15 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.475251","level":"info","event":"25/09/02 16:38:15 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.531730","level":"info","event":"25/09/02 16:38:15 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.541877","level":"info","event":"25/09/02 16:38:15 INFO Utils: Successfully started service 'SparkUI' on port 4041.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.573874","level":"info","event":"25/09/02 16:38:15 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar at spark://b1b4c0de2c56:41193/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar with timestamp 1756831094943","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.574060","level":"info","event":"25/09/02 16:38:15 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar at spark://b1b4c0de2c56:41193/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar with timestamp 1756831094943","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.574405","level":"info","event":"25/09/02 16:38:15 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar at spark://b1b4c0de2c56:41193/jars/org.apache.kafka_kafka-clients-3.4.1.jar with timestamp 1756831094943","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.574490","level":"info","event":"25/09/02 16:38:15 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://b1b4c0de2c56:41193/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1756831094943","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.574539","level":"info","event":"25/09/02 16:38:15 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar at spark://b1b4c0de2c56:41193/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1756831094943","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.574657","level":"info","event":"25/09/02 16:38:15 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar at spark://b1b4c0de2c56:41193/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1756831094943","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.574766","level":"info","event":"25/09/02 16:38:15 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar at spark://b1b4c0de2c56:41193/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1756831094943","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.574874","level":"info","event":"25/09/02 16:38:15 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar at spark://b1b4c0de2c56:41193/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1756831094943","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.574985","level":"info","event":"25/09/02 16:38:15 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar at spark://b1b4c0de2c56:41193/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1756831094943","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.575095","level":"info","event":"25/09/02 16:38:15 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar at spark://b1b4c0de2c56:41193/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1756831094943","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.575250","level":"info","event":"25/09/02 16:38:15 INFO SparkContext: Added JAR file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://b1b4c0de2c56:41193/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1756831094943","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.577814","level":"info","event":"25/09/02 16:38:15 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar at spark://b1b4c0de2c56:41193/files/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar with timestamp 1756831094943","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.578989","level":"info","event":"25/09/02 16:38:15 INFO Utils: Copying /root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar to /tmp/spark-fe5897da-8f6a-4bde-b3d2-46e1a82fb0c8/userFiles-972ee837-df58-4b06-b344-0a4d77fec36d/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.585720","level":"info","event":"25/09/02 16:38:15 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar at spark://b1b4c0de2c56:41193/files/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar with timestamp 1756831094943","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.586026","level":"info","event":"25/09/02 16:38:15 INFO Utils: Copying /root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar to /tmp/spark-fe5897da-8f6a-4bde-b3d2-46e1a82fb0c8/userFiles-972ee837-df58-4b06-b344-0a4d77fec36d/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.589599","level":"info","event":"25/09/02 16:38:15 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar at spark://b1b4c0de2c56:41193/files/org.apache.kafka_kafka-clients-3.4.1.jar with timestamp 1756831094943","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.589750","level":"info","event":"25/09/02 16:38:15 INFO Utils: Copying /root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar to /tmp/spark-fe5897da-8f6a-4bde-b3d2-46e1a82fb0c8/userFiles-972ee837-df58-4b06-b344-0a4d77fec36d/org.apache.kafka_kafka-clients-3.4.1.jar","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.597625","level":"info","event":"25/09/02 16:38:15 INFO SparkContext: Added file file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://b1b4c0de2c56:41193/files/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1756831094943","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.597775","level":"info","event":"25/09/02 16:38:15 INFO Utils: Copying /root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar to /tmp/spark-fe5897da-8f6a-4bde-b3d2-46e1a82fb0c8/userFiles-972ee837-df58-4b06-b344-0a4d77fec36d/com.google.code.findbugs_jsr305-3.0.0.jar","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.601134","level":"info","event":"25/09/02 16:38:15 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar at spark://b1b4c0de2c56:41193/files/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1756831094943","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.601298","level":"info","event":"25/09/02 16:38:15 INFO Utils: Copying /root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar to /tmp/spark-fe5897da-8f6a-4bde-b3d2-46e1a82fb0c8/userFiles-972ee837-df58-4b06-b344-0a4d77fec36d/org.apache.commons_commons-pool2-2.11.1.jar","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.605716","level":"info","event":"25/09/02 16:38:15 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar at spark://b1b4c0de2c56:41193/files/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1756831094943","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.605875","level":"info","event":"25/09/02 16:38:15 INFO Utils: Copying /root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar to /tmp/spark-fe5897da-8f6a-4bde-b3d2-46e1a82fb0c8/userFiles-972ee837-df58-4b06-b344-0a4d77fec36d/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.634401","level":"info","event":"25/09/02 16:38:15 INFO SparkContext: Added file file:///root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar at spark://b1b4c0de2c56:41193/files/org.lz4_lz4-java-1.8.0.jar with timestamp 1756831094943","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.634580","level":"info","event":"25/09/02 16:38:15 INFO Utils: Copying /root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar to /tmp/spark-fe5897da-8f6a-4bde-b3d2-46e1a82fb0c8/userFiles-972ee837-df58-4b06-b344-0a4d77fec36d/org.lz4_lz4-java-1.8.0.jar","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.638968","level":"info","event":"25/09/02 16:38:15 INFO SparkContext: Added file file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar at spark://b1b4c0de2c56:41193/files/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1756831094943","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.639175","level":"info","event":"25/09/02 16:38:15 INFO Utils: Copying /root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar to /tmp/spark-fe5897da-8f6a-4bde-b3d2-46e1a82fb0c8/userFiles-972ee837-df58-4b06-b344-0a4d77fec36d/org.xerial.snappy_snappy-java-1.1.10.3.jar","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.643865","level":"info","event":"25/09/02 16:38:15 INFO SparkContext: Added file file:///root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar at spark://b1b4c0de2c56:41193/files/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1756831094943","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.644017","level":"info","event":"25/09/02 16:38:15 INFO Utils: Copying /root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar to /tmp/spark-fe5897da-8f6a-4bde-b3d2-46e1a82fb0c8/userFiles-972ee837-df58-4b06-b344-0a4d77fec36d/org.slf4j_slf4j-api-2.0.7.jar","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.646984","level":"info","event":"25/09/02 16:38:15 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar at spark://b1b4c0de2c56:41193/files/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1756831094943","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.647115","level":"info","event":"25/09/02 16:38:15 INFO Utils: Copying /root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar to /tmp/spark-fe5897da-8f6a-4bde-b3d2-46e1a82fb0c8/userFiles-972ee837-df58-4b06-b344-0a4d77fec36d/org.apache.hadoop_hadoop-client-api-3.3.4.jar","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.665336","level":"info","event":"25/09/02 16:38:15 INFO SparkContext: Added file file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://b1b4c0de2c56:41193/files/commons-logging_commons-logging-1.1.3.jar with timestamp 1756831094943","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.665664","level":"info","event":"25/09/02 16:38:15 INFO Utils: Copying /root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar to /tmp/spark-fe5897da-8f6a-4bde-b3d2-46e1a82fb0c8/userFiles-972ee837-df58-4b06-b344-0a4d77fec36d/commons-logging_commons-logging-1.1.3.jar","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.726365","level":"info","event":"25/09/02 16:38:15 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.757419","level":"info","event":"25/09/02 16:38:15 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.24:7077 after 18 ms (0 ms spent in bootstraps)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.832200","level":"info","event":"25/09/02 16:38:15 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250902163815-0005","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.841237","level":"info","event":"25/09/02 16:38:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37651.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.841423","level":"info","event":"25/09/02 16:38:15 INFO NettyBlockTransferService: Server created on b1b4c0de2c56:37651","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.842893","level":"info","event":"25/09/02 16:38:15 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.848664","level":"info","event":"25/09/02 16:38:15 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, b1b4c0de2c56, 37651, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.851570","level":"info","event":"25/09/02 16:38:15 INFO BlockManagerMasterEndpoint: Registering block manager b1b4c0de2c56:37651 with 434.4 MiB RAM, BlockManagerId(driver, b1b4c0de2c56, 37651, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.853756","level":"info","event":"25/09/02 16:38:15 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, b1b4c0de2c56, 37651, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:15.855286","level":"info","event":"25/09/02 16:38:15 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, b1b4c0de2c56, 37651, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:16.031400","level":"info","event":"25/09/02 16:38:16 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:16.216316","level":"info","event":"INFO:__main__:Spark session started","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:16.222280","level":"info","event":"25/09/02 16:38:16 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:16.224090","level":"info","event":"25/09/02 16:38:16 INFO SharedState: Warehouse path is 'file:/tmp/airflowtmp6pm77_8t/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.025259","level":"info","event":"ERROR:__main__:Fatal error in bronze-orders: An error occurred while calling o58.start.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.025539","level":"info","event":": org.apache.spark.SparkClassNotFoundException: [DATA_SOURCE_NOT_FOUND] Failed to find the data source: delta. Please find packages at `https://spark.apache.org/third-party-projects.html`.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.025652","level":"info","event":"\tat org.apache.spark.sql.errors.QueryExecutionErrors$.dataSourceNotFoundError(QueryExecutionErrors.scala:724)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.025727","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:647)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.025798","level":"info","event":"\tat org.apache.spark.sql.streaming.DataStreamWriter.startInternal(DataStreamWriter.scala:370)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.025863","level":"info","event":"\tat org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:233)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.025931","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.026003","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.026073","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.026151","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.026202","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.026242","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.026302","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.026383","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.026457","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.026521","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.026583","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.026646","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.026712","level":"info","event":"Caused by: java.lang.ClassNotFoundException: delta.DefaultSource","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.026786","level":"info","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.026860","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.026935","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.027002","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:633)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.027076","level":"info","event":"\tat scala.util.Try$.apply(Try.scala:213)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.027150","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:633)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.027219","level":"info","event":"\tat scala.util.Failure.orElse(Try.scala:224)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.027295","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:633)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.027371","level":"info","event":"\t... 14 more","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.027450","level":"info","event":"Traceback (most recent call last):","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.027570","level":"info","event":"  File \"/opt/jobs/bronze_orders.py\", line 62, in main","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.027647","level":"info","event":"    .start(sink_path))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.027702","level":"info","event":"     ^^^^^^^^^^^^^^^^","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.027767","level":"info","event":"  File \"/opt/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py\", line 1529, in start","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.027891","level":"info","event":"    return self._sq(self._jwrite.start(path))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.027958","level":"info","event":"                    ^^^^^^^^^^^^^^^^^^^^^^^^","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.028032","level":"info","event":"  File \"/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1322, in __call__","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.028105","level":"info","event":"    return_value = get_return_value(","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.028172","level":"info","event":"                   ^^^^^^^^^^^^^^^^^","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.028236","level":"info","event":"  File \"/opt/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py\", line 179, in deco","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.028334","level":"info","event":"    return f(*a, **kw)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.028404","level":"info","event":"           ^^^^^^^^^^^","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.028470","level":"info","event":"  File \"/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py\", line 326, in get_return_value","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.028537","level":"info","event":"    raise Py4JJavaError(","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.028605","level":"info","event":"py4j.protocol.Py4JJavaError: An error occurred while calling o58.start.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.028680","level":"info","event":": org.apache.spark.SparkClassNotFoundException: [DATA_SOURCE_NOT_FOUND] Failed to find the data source: delta. Please find packages at `https://spark.apache.org/third-party-projects.html`.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.028755","level":"info","event":"\tat org.apache.spark.sql.errors.QueryExecutionErrors$.dataSourceNotFoundError(QueryExecutionErrors.scala:724)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.028824","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:647)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.028898","level":"info","event":"\tat org.apache.spark.sql.streaming.DataStreamWriter.startInternal(DataStreamWriter.scala:370)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.028974","level":"info","event":"\tat org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:233)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.029048","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.029125","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.029198","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.029265","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.029331","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.029415","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.029475","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.029566","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.029641","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.029708","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.029802","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.029860","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.029899","level":"info","event":"Caused by: java.lang.ClassNotFoundException: delta.DefaultSource","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.029937","level":"info","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.029973","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.030026","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.030081","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:633)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.030136","level":"info","event":"\tat scala.util.Try$.apply(Try.scala:213)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.030179","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:633)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.030246","level":"info","event":"\tat scala.util.Failure.orElse(Try.scala:224)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.030299","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:633)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.030343","level":"info","event":"\t... 14 more","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.030406","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.030463","level":"info","event":"Traceback (most recent call last):","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.030514","level":"info","event":"  File \"/opt/jobs/bronze_orders.py\", line 72, in <module>","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.030571","level":"info","event":"    main()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.030627","level":"info","event":"  File \"/opt/jobs/bronze_orders.py\", line 62, in main","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.030696","level":"info","event":"    .start(sink_path))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.030757","level":"info","event":"     ^^^^^^^^^^^^^^^^","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.030821","level":"info","event":"  File \"/opt/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py\", line 1529, in start","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.030888","level":"info","event":"  File \"/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1322, in __call__","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.030959","level":"info","event":"  File \"/opt/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py\", line 179, in deco","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.031034","level":"info","event":"  File \"/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py\", line 326, in get_return_value","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.031985","level":"info","event":"py4j.protocol.Py4JJavaError: An error occurred while calling o58.start.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.032152","level":"info","event":": org.apache.spark.SparkClassNotFoundException: [DATA_SOURCE_NOT_FOUND] Failed to find the data source: delta. Please find packages at `https://spark.apache.org/third-party-projects.html`.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.032242","level":"info","event":"\tat org.apache.spark.sql.errors.QueryExecutionErrors$.dataSourceNotFoundError(QueryExecutionErrors.scala:724)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.032312","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:647)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.032363","level":"info","event":"\tat org.apache.spark.sql.streaming.DataStreamWriter.startInternal(DataStreamWriter.scala:370)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.032405","level":"info","event":"\tat org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:233)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.032443","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.032482","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.032524","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.032588","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.032660","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.032712","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.032772","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.032832","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.032885","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.032933","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.032993","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.033039","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.033085","level":"info","event":"Caused by: java.lang.ClassNotFoundException: delta.DefaultSource","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.033124","level":"info","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.033160","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.033217","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.033283","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:633)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.033352","level":"info","event":"\tat scala.util.Try$.apply(Try.scala:213)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.033418","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:633)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.033496","level":"info","event":"\tat scala.util.Failure.orElse(Try.scala:224)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.033576","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:633)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.033657","level":"info","event":"\t... 14 more","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.033728","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.033774","level":"info","event":"INFO:py4j.clientserver:Closing down clientserver connection","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.098035","level":"info","event":"25/09/02 16:38:18 INFO SparkContext: Invoking stop() from shutdown hook","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.098201","level":"info","event":"25/09/02 16:38:18 INFO SparkContext: SparkContext is stopping with exitCode 0.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.107621","level":"info","event":"25/09/02 16:38:18 INFO SparkUI: Stopped Spark web UI at http://b1b4c0de2c56:4041","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.111064","level":"info","event":"25/09/02 16:38:18 INFO StandaloneSchedulerBackend: Shutting down all executors","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.115840","level":"info","event":"25/09/02 16:38:18 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.130309","level":"info","event":"25/09/02 16:38:18 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.142305","level":"info","event":"25/09/02 16:38:18 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.142699","level":"info","event":"25/09/02 16:38:18 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.147786","level":"info","event":"25/09/02 16:38:18 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.149650","level":"info","event":"25/09/02 16:38:18 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.171513","level":"info","event":"25/09/02 16:38:18 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.171941","level":"info","event":"25/09/02 16:38:18 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.172927","level":"info","event":"25/09/02 16:38:18 INFO ShutdownHookManager: Deleting directory /tmp/spark-076ce8a4-1948-4cad-9fdb-6ba3ccb3853c","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.176570","level":"info","event":"25/09/02 16:38:18 INFO ShutdownHookManager: Deleting directory /tmp/spark-fe5897da-8f6a-4bde-b3d2-46e1a82fb0c8/pyspark-b559387a-4a57-44ec-9d06-fbcd6a770bed","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.180351","level":"info","event":"25/09/02 16:38:18 INFO ShutdownHookManager: Deleting directory /tmp/spark-fe5897da-8f6a-4bde-b3d2-46e1a82fb0c8","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.210445","level":"info","event":"Command exited with return code 1","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T16:38:18.211312","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"AirflowException","exc_value":"Bash command failed. The command returned a non-zero exit code 1.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/opt/bitnami/airflow/venv/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":918,"name":"run"},{"filename":"/opt/bitnami/airflow/venv/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1213,"name":"_execute_task"},{"filename":"/opt/bitnami/airflow/venv/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":397,"name":"wrapper"},{"filename":"/opt/bitnami/airflow/venv/lib/python3.12/site-packages/airflow/providers/standard/operators/bash.py","lineno":232,"name":"execute"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2025-09-02T16:38:18.238430Z","level":"info","event":"Task instance in failure state","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-02T16:38:18.238999Z","level":"info","event":"Task start","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-02T16:38:18.239384Z","level":"info","event":"Task:<Task(BashOperator): orders_bronze_stream>","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-02T16:38:18.239604Z","level":"info","event":"Failure caused by Bash command failed. The command returned a non-zero exit code 1.","chan":"stdout","logger":"task"}

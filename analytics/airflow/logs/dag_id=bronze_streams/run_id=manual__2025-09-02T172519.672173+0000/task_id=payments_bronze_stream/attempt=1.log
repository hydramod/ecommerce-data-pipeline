{"timestamp":"2025-09-02T17:25:21.318021","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-09-02T17:25:21.318627","level":"info","event":"Filling up the DagBag from /opt/bitnami/airflow/dags/rt_pipeline.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-02T17:25:23.053824Z","level":"info","event":"Task instance is in running state","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-02T17:25:23.054246Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-02T17:25:23.054493Z","level":"info","event":"Current task name:payments_bronze_stream","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-02T17:25:23.056624Z","level":"info","event":"Dag name:bronze_streams","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-02T17:25:23.057800","level":"info","event":"Tmp dir root location: /tmp","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T17:25:23.059026","level":"info","event":"Running command: ['/usr/bin/bash', '-c', '/opt/spark/bin/spark-submit --master spark://spark-master:7077 --deploy-mode client --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,io.delta:delta-core_2.12:2.4.0 /opt/jobs/bronze_payments.py']","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T17:25:23.071439","level":"info","event":"Output:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T17:25:23.084022","level":"info","event":"NWRAP_ERROR[<unknown> (86)] - nwrap_files_cache_reload: Unable to open '/opt/bitnami/airflow/nss-wrapper/nss_passwd' readonly -1:No such file or directory","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T17:25:23.084195","level":"info","event":"NWRAP_ERROR[<unknown> (86)] - nwrap_files_getpwuid: Error loading passwd file","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T17:25:23.103634","level":"info","event":"NWRAP_ERROR[<unknown> (86)] - nwrap_files_cache_reload: Unable to open '/opt/bitnami/airflow/nss-wrapper/nss_passwd' readonly -1:No such file or directory","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T17:25:23.103818","level":"info","event":"NWRAP_ERROR[<unknown> (86)] - nwrap_files_getpwuid: Error loading passwd file","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T17:25:23.278826","level":"info","event":"NWRAP_ERROR[<unknown> (82)] - nwrap_files_cache_reload: Unable to open '/opt/bitnami/airflow/nss-wrapper/nss_passwd' readonly -1:No such file or directory","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T17:25:23.279057","level":"info","event":"NWRAP_ERROR[<unknown> (82)] - nwrap_files_getpwuid: Error loading passwd file","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T17:25:23.292696","level":"info","event":"NWRAP_ERROR[<unknown> (82)] - nwrap_files_cache_reload: Unable to open '/opt/bitnami/airflow/nss-wrapper/nss_passwd' readonly -1:No such file or directory","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T17:25:23.292862","level":"info","event":"NWRAP_ERROR[<unknown> (82)] - nwrap_files_getpwuid: Error loading passwd file","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T17:25:24.490205","level":"info","event":"Warning: Ignoring non-Spark config property: hive.metastore.uris","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T17:25:24.699276","level":"info","event":"Exception in thread \"main\" java.lang.IllegalArgumentException: basedir must be absolute: ?/.ivy2/local","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T17:25:24.699426","level":"info","event":"\tat org.apache.ivy.util.Checks.checkAbsolute(Checks.java:48)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T17:25:24.699505","level":"info","event":"\tat org.apache.ivy.plugins.repository.file.FileRepository.setBaseDir(FileRepository.java:137)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T17:25:24.699569","level":"info","event":"\tat org.apache.ivy.plugins.repository.file.FileRepository.<init>(FileRepository.java:44)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T17:25:24.699646","level":"info","event":"\tat org.apache.spark.deploy.SparkSubmitUtils$.createRepoResolvers(SparkSubmit.scala:1269)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T17:25:24.699688","level":"info","event":"\tat org.apache.spark.deploy.SparkSubmitUtils$.buildIvySettings(SparkSubmit.scala:1376)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T17:25:24.699742","level":"info","event":"\tat org.apache.spark.util.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:182)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T17:25:24.699801","level":"info","event":"\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:334)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T17:25:24.699845","level":"info","event":"\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:964)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T17:25:24.699885","level":"info","event":"\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:194)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T17:25:24.699923","level":"info","event":"\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:217)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T17:25:24.699959","level":"info","event":"\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T17:25:24.700005","level":"info","event":"\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1120)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T17:25:24.700088","level":"info","event":"\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1129)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T17:25:24.700155","level":"info","event":"\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T17:25:24.706122","level":"info","event":"Command exited with return code 1","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-09-02T17:25:24.706706","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"AirflowException","exc_value":"Bash command failed. The command returned a non-zero exit code 1.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/opt/bitnami/airflow/venv/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":918,"name":"run"},{"filename":"/opt/bitnami/airflow/venv/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1213,"name":"_execute_task"},{"filename":"/opt/bitnami/airflow/venv/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":397,"name":"wrapper"},{"filename":"/opt/bitnami/airflow/venv/lib/python3.12/site-packages/airflow/providers/standard/operators/bash.py","lineno":232,"name":"execute"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2025-09-02T17:25:24.732199Z","level":"info","event":"Task instance in failure state","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-02T17:25:24.732659Z","level":"info","event":"Task start","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-02T17:25:24.733180Z","level":"info","event":"Task:<Task(BashOperator): payments_bronze_stream>","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-02T17:25:24.733577Z","level":"info","event":"Failure caused by Bash command failed. The command returned a non-zero exit code 1.","chan":"stdout","logger":"task"}
